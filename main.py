import os
import tempfile
from collections import defaultdict
from dotenv import load_dotenv
import streamlit as st
from openai import OpenAI

# Importy w≈Çasnych modu≈Ç√≥w (upewnij siƒô, ≈ºe struktura katalog√≥w jest poprawna)
from src.log_parser import parse_log_file
from src.risk_analyzer import tag_logs_with_risk
from src.batcher import batch_logs

# ≈Åadowanie konfiguracji z pliku .env (je≈õli istnieje)
load_dotenv()

# Funkcja grupujƒÖca logi typu brute force
def group_similar_risks(logs):
    grouped = defaultdict(list)
    for i, log in enumerate(logs):
        if log['risk'] == "Possible Brute Force":
            key = (log['ip'], log['method'], log['path'], log['status'])
            grouped[key].append((i + 1, log))  # zapis numeru linii i wpisu

    grouped_entries = []
    used_lines = set()

    for (ip, method, path, status), entries in grouped.items():
        if len(entries) >= 3:
            line_numbers = [idx for idx, _ in entries]
            # Za≈Ç√≥≈ºmy, ≈ºe daty sƒÖ rozdzielone dwukropkami; pobieramy godziny i minuty
            timestamps = [":".join(log['datetime'].split(":")[1:3]) for _, log in entries]
            sample_log = entries[0][1]
            grouped_entries.append({
                "lines": line_numbers,
                "risk": "Brute Force (grupowane)",
                "summary": f"{len(entries)}x {method} {path} {status} z IP {ip}",
                "original": sample_log,
                "line": line_numbers[0],
                "count": len(entries),
                "timestamps": timestamps
            })
            used_lines.update(line_numbers)

    return grouped_entries, used_lines

# Funkcja formatujƒÖca prompt do analizy przez GPT
def format_prompt(logs):
    prompt = (
        "Poni≈ºej znajduje siƒô lista podejrzanych wpis√≥w z logu serwera Apache. "
        "Dla ka≈ºdego z nich wykonaj **kr√≥tkƒÖ, profesjonalnƒÖ analizƒô** w formacie Markdown.\n\n"
        "Dla ka≈ºdego logu:\n"
        "- Okre≈õl typ ataku (np. SQL Injection, XSS, Directory Traversal, itp.) ‚Äì je≈õli dotyczy\n"
        "- Wyja≈õnij, na czym polega zagro≈ºenie\n"
        "- Zaproponuj jedno lub dwa konkretne dzia≈Çania dla administratora\n\n"
        "Je≈õli dany log **nie zawiera zagro≈ºenia**, napisz w odpowiedzi:\n"
        "`Nie wykryto zagro≈ºenia: (wyja≈õnienie co oznacza wpis)`\n\n"
        "### Format odpowiedzi:\n"
        "### [12] SQL Injection\n"
        "`GET /products.php?id=1' OR '1'='1 200`\n"
        "Ten log zawiera pr√≥bƒô SQL Injection przy u≈ºyciu operatora OR. Mo≈ºe umo≈ºliwiƒá dostƒôp do bazy danych.\n"
        "**Zalecenia:** Wprowadziƒá parametryzacjƒô zapyta≈Ñ SQL i walidacjƒô danych wej≈õciowych.\n\n"
        "### Logi do analizy:\n"
    )
    for log in logs:
        line = log['line']
        details = f"{log['method']} {log['path']} {log['status']}"
        if log.get("extra"):
            details += f" {log['extra']}"
        prompt += f"{line}. {details}\n"
    return prompt

# Funkcja wysy≈ÇajƒÖca prompt do OpenAI i zbierajƒÖca odpowiedzi
def analyze_logs_with_openai(client, logs):
    if not logs:
        return "Brak podejrzanych log√≥w do analizy."

    batched = list(batch_logs(logs, batch_size=20))
    all_responses = []

    try:
        for batch in batched:
            prompt = format_prompt(batch)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content":
                        "Jeste≈õ ekspertem ds. cyberbezpiecze≈Ñstwa. Twoim zadaniem jest analiza log√≥w serwera Apache. "
                        "Zwr√≥ƒá wynik w dok≈Çadnie okre≈õlonym formacie Markdown, zgodnie z poleceniem u≈ºytkownika. "
                        "Nie dodawaj ≈ºadnych wstƒôp√≥w ani podsumowa≈Ñ."},
                    {"role": "user", "content": prompt}
                ]
            )
            all_responses.append(response.choices[0].message.content.strip())
    except Exception as e:
        return f"‚ùå B≈ÇƒÖd API OpenAI: {str(e)}"

    return "\n\n".join(all_responses)

# Funkcja g≈Ç√≥wna wykonujƒÖca analizƒô log√≥w i generujƒÖca raport
def run_analysis(log_file_path, client):
    # Wczytywanie oraz przetwarzanie log√≥w
    parsed_logs = parse_log_file(log_file_path)
    tagged_logs = tag_logs_with_risk(parsed_logs)

    # Grupowanie wpis√≥w typu brute force
    grouped_brute, used_lines = group_similar_risks(tagged_logs)

    # Wyb√≥r log√≥w, kt√≥re nie nale≈ºƒÖ do zgrupowanych
    flat_logs = []
    for i, log in enumerate(tagged_logs, 1):
        if log['risk'] != "OK" and i not in used_lines:
            flat_logs.append({
                "line": i,
                "method": log["method"],
                "path": log["path"],
                "status": log["status"],
                "extra": ""
            })

    # Dodanie zgrupowanych log√≥w jako reprezentatywnych do analizy GPT
    logs_for_gpt = []
    for group in grouped_brute:
        logs_for_gpt.append({
            "line": group["line"],
            "method": group["original"]["method"],
            "path": group["original"]["path"],
            "status": group["original"]["status"],
            "extra": f"(WystƒÖpi≈Ço {group['count']} razy w godzinach: {', '.join(group['timestamps'])})"
        })
    logs_for_gpt.extend(flat_logs)

    # Budowanie raportu
    report_lines = ["# üõ°Ô∏è Raport zagro≈ºe≈Ñ (heurystyki + analiza GPT)\n"]

    if not (flat_logs or grouped_brute):
        report_lines.append("‚úÖ Brak podejrzanych log√≥w wykrytych przez heurystyki.\n")
    else:
        report_lines.append("## üîç Wykryte podejrzane logi (heurystyki):\n")
        for group in grouped_brute:
            lines_str = ", ".join(map(str, group["lines"]))
            report_lines.append(f"- **[linie: {lines_str}]** `{group['summary']}` ‚Üí **{group['risk']}**")

        for i, log in enumerate(tagged_logs, 1):
            if log['risk'] != "OK" and i not in used_lines:
                report_lines.append(f"- **[{i}]** `{log['method']} {log['path']} {log['status']}` ‚Üí **{log['risk']}**")

        report_lines.append("\n## ü§ñ Analiza przez GPT-4:\n")
        gpt_output = analyze_logs_with_openai(client, logs_for_gpt)
        report_lines.append(gpt_output)

    return "\n".join(report_lines)

# Konfiguracja aplikacji Streamlit
st.title("Analiza Log√≥w Serwera")
st.write("Prze≈õlij plik z logami lub skorzystaj z domy≈õlnego pliku, aby przeprowadziƒá analizƒô zagro≈ºe≈Ñ.")

# Opcja wyboru ≈∫r√≥d≈Ça pliku log√≥w
log_source = st.radio(
    "≈πr√≥d≈Ço log√≥w:",
    ("Domy≈õlny plik", "Wgraj plik"),
    index=0
)

tmp_file_path = None

if log_source == "Domy≈õlny plik":
    default_path = os.path.join("data", "synthetic_apache.log")
    if os.path.exists(default_path):
        tmp_file_path = default_path
        st.info(f"U≈ºywany domy≈õlny plik log√≥w: {default_path}")
    else:
        st.error(f"Domy≈õlny plik nie zosta≈Ç znaleziony pod ≈õcie≈ºkƒÖ: {default_path}")
else:
    uploaded_file = st.file_uploader("Wybierz plik z logami (.log lub .txt)", type=["log", "txt"])
    if uploaded_file is not None:
        # Zapisujemy przes≈Çany plik do tymczasowego pliku
        with tempfile.NamedTemporaryFile(delete=False, suffix=".log") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name
        st.success("Plik zosta≈Ç wczytany pomy≈õlnie.")

# Obs≈Çuga klucza API ‚Äì pr√≥ba pobrania z pliku .env lub rƒôczne wprowadzenie
api_key = os.getenv("OPENAI_API_KEY") or st.text_input("Wprowad≈∫ klucz API OpenAI", type="password")
if not api_key:
    st.error("Klucz API OpenAI nie jest ustawiony. Uzupe≈Çnij pole powy≈ºej.")
    st.stop()

# Inicjalizacja klienta OpenAI
client = OpenAI(api_key=api_key)

# Przycisk do uruchomienia analizy
if tmp_file_path:
    if st.button("Analizuj logi"):
        with st.spinner("Przetwarzanie log√≥w i generowanie raportu..."):
            report = run_analysis(tmp_file_path, client)
        st.markdown(report)
        st.download_button(
            label="Pobierz raport",
            data=report,
            file_name="threat_report.md",
            mime="text/markdown"
        )
else:
    st.info("Proszƒô wybraƒá ≈∫r√≥d≈Ço log√≥w, aby rozpoczƒÖƒá analizƒô.")
